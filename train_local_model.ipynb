{"cells":[{"cell_type":"markdown","metadata":{"id":"MwOH7y-Q4Qx9"},"source":["# Finetuning a DCNN to detect landfills in the Litoral Region in Argentina"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uL2SH35XA9mJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743104740975,"user_tz":180,"elapsed":21834,"user":{"displayName":"Rodrigo Echeveste","userId":"13291271408897853643"}},"outputId":"688884e1-1320-40f0-f8b0-3adafcfb52da"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import sys, os"],"metadata":{"id":"VXr7OVZ-oQoW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["project_directory = \"/content/drive/MyDrive/Trabajo/Proyectos/Basurales_Carla/cientibeca\"\n","os.chdir(project_directory)\n","print(f\"Current working directory: {os.getcwd()}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dalPDNqYpCw1","executionInfo":{"status":"ok","timestamp":1743104741153,"user_tz":180,"elapsed":180,"user":{"displayName":"Rodrigo Echeveste","userId":"13291271408897853643"}},"outputId":"f3e19d9b-411b-42b5-9a7b-3d32ed9e17a1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Current working directory: /content/drive/MyDrive/Trabajo/Proyectos/Basurales_Carla\n"]}]},{"cell_type":"markdown","metadata":{"id":"GdGeoanR4QyF"},"source":["# Loading architecture and pre-trained weights"]},{"cell_type":"code","source":["!pip install pytorch-ignite"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hG9TjqHnDv1s","executionInfo":{"status":"ok","timestamp":1743104833682,"user_tz":180,"elapsed":92527,"user":{"displayName":"Rodrigo Echeveste","userId":"13291271408897853643"}},"outputId":"42f9e25a-764b-406d-838f-efeb92eada2d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pytorch-ignite\n","  Downloading pytorch_ignite-0.5.1-py3-none-any.whl.metadata (27 kB)\n","Requirement already satisfied: torch<3,>=1.3 in /usr/local/lib/python3.11/dist-packages (from pytorch-ignite) (2.6.0+cu124)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from pytorch-ignite) (24.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.3->pytorch-ignite) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.3->pytorch-ignite) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.3->pytorch-ignite) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.3->pytorch-ignite) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.3->pytorch-ignite) (2025.3.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3,>=1.3->pytorch-ignite)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3,>=1.3->pytorch-ignite)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3,>=1.3->pytorch-ignite)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3,>=1.3->pytorch-ignite)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3,>=1.3->pytorch-ignite)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3,>=1.3->pytorch-ignite)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3,>=1.3->pytorch-ignite)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3,>=1.3->pytorch-ignite)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3,>=1.3->pytorch-ignite)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.3->pytorch-ignite) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.3->pytorch-ignite) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.3->pytorch-ignite) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3,>=1.3->pytorch-ignite)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.3->pytorch-ignite) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.3->pytorch-ignite) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=1.3->pytorch-ignite) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=1.3->pytorch-ignite) (3.0.2)\n","Downloading pytorch_ignite-0.5.1-py3-none-any.whl (312 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.7/312.7 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m91.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m91.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, pytorch-ignite\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pytorch-ignite-0.5.1\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yPrHdM7w4QyG","executionInfo":{"status":"ok","timestamp":1743105434631,"user_tz":180,"elapsed":796,"user":{"displayName":"Rodrigo Echeveste","userId":"13291271408897853643"}},"outputId":"e6a74e69-5559-425c-8714-8c718d47260c"},"outputs":[{"output_type":"stream","name":"stdout","text":["pretrained\n"]},{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":13}],"source":["import torch\n","\n","sys.path.append(os.path.join(project_directory, 'modelo_italia'))\n","\n","# Importing model definition\n","from architecture.resnet50_fpn import Net\n","\n","# Loading state dictionary\n","STATE_DICT_PATH = \"modelo_italia/weights/checkpoint.pth\"\n","\n","# Creating an instance of the model\n","model = Net(num_classes=1)\n","\n","# Loading the weights into the model\n","model.load_state_dict(torch.load(STATE_DICT_PATH, map_location=torch.device('cpu')))"]},{"cell_type":"code","source":["# Freeze all layers except the last two fc layers\n","for name, param in model.named_parameters():\n","    if not ('fc' in name or 'classifier' in name): # Freeze if not an fc layer in classifier\n","        param.requires_grad = False\n","    else:\n","        param.requires_grad = True\n","\n","# Print trainable parameters to verify\n","for name, param in model.named_parameters():\n","    if param.requires_grad:\n","        print(name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pdj-2lH6ux8i","executionInfo":{"status":"ok","timestamp":1743105434640,"user_tz":180,"elapsed":7,"user":{"displayName":"Rodrigo Echeveste","userId":"13291271408897853643"}},"outputId":"245e5465-7998-4238-a315-1c87d923c407"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["fc.weight\n","fc.bias\n","classifier.weight\n","classifier.bias\n"]}]},{"cell_type":"markdown","metadata":{"id":"po2KLpeG4QyG"},"source":["# Loading data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tr4isnzP4QyH"},"outputs":[],"source":["import pandas as pd\n","db_parana = pd.read_csv(\"labels/parana_labels.csv\")\n","db_rosario = pd.read_csv(\"labels/rosario_labels.csv\")\n","db_santafe = pd.read_csv(\"labels/santafe_labels.csv\")"]},{"cell_type":"code","source":["from torch.utils.data import Dataset\n","from PIL import Image\n","from torchvision import transforms\n","\n","class CustomImageDataset(Dataset):\n","    def __init__(self, dataframe, img_dir):\n","        \"\"\"\n","        Args:\n","            dataframe (pandas.DataFrame): DataFrame containing image file names and labels.\n","            img_dir (str): Directory containing the images.\n","        \"\"\"\n","        self.img_labels = dataframe[['file_name', 'etiqueta']]\n","        self.img_dir = img_dir\n","        # Transforms for ResNet50\n","        self.transform = transforms.Compose([\n","            transforms.Resize(800), # Images are resized to 800x800 using the same resolution as inTorres et al. (2023)\n","            transforms.RandomHorizontalFlip(),  # Random horizontal flips as in Torres et al. (2023)\n","            transforms.RandomRotation(90), # Random 90-degree rotations as in Torres et al. (2023)\n","            transforms.ToTensor(),\n","            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                                 std=[0.229, 0.224, 0.225])  # ImageNet normalization\n","        ])\n","\n","    def __len__(self):\n","        return len(self.img_labels)\n","\n","    def __getitem__(self, idx):\n","        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n","        image = Image.open(img_path).convert('RGB')\n","        label = self.img_labels.iloc[idx, 1]\n","\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        return image, label\n","\n","\n","parana_dataset = CustomImageDataset(db_parana, 'images/parana/patches_parana')\n","rosario_dataset = CustomImageDataset(db_rosario, 'images/rosario/patches_ros')\n","santafe_dataset = CustomImageDataset(db_santafe, 'images/santa_fe/patches_sfe')"],"metadata":{"id":"4bOzT7W40Y3q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(len(parana_dataset), len(rosario_dataset), len(santafe_dataset))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ux5v4Utg0xic","executionInfo":{"status":"ok","timestamp":1743105436732,"user_tz":180,"elapsed":8,"user":{"displayName":"Rodrigo Echeveste","userId":"13291271408897853643"}},"outputId":"02e53279-2d18-40bb-bcc5-de476ebee200"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["290 320 370\n"]}]},{"cell_type":"code","source":["# Separate each into train val test\n","from torch.utils.data import random_split\n","\n","# Split ratios\n","train_ratio = 0.6\n","val_ratio = 0.20\n","test_ratio = 0.20\n","\n","# Split parana_dataset\n","parana_train_size = int(train_ratio * len(parana_dataset))\n","parana_val_size = int(val_ratio * len(parana_dataset))\n","parana_test_size = len(parana_dataset) - parana_train_size - parana_val_size\n","parana_train_dataset, parana_val_dataset, parana_test_dataset = random_split(\n","    parana_dataset, [parana_train_size, parana_val_size, parana_test_size]\n",")\n","\n","# Split rosario_dataset\n","rosario_train_size = int(train_ratio * len(rosario_dataset))\n","rosario_val_size = int(val_ratio * len(rosario_dataset))\n","rosario_test_size = len(rosario_dataset) - rosario_train_size - rosario_val_size\n","rosario_train_dataset, rosario_val_dataset, rosario_test_dataset = random_split(\n","    rosario_dataset, [rosario_train_size, rosario_val_size, rosario_test_size]\n",")\n","\n","# Split santafe_dataset\n","santafe_train_size = int(train_ratio * len(santafe_dataset))\n","santafe_val_size = int(val_ratio * len(santafe_dataset))\n","santafe_test_size = len(santafe_dataset) - santafe_train_size - santafe_val_size\n","santafe_train_dataset, santafe_val_dataset, santafe_test_dataset = random_split(\n","    santafe_dataset, [santafe_train_size, santafe_val_size, santafe_test_size]\n",")\n","\n","print(f\"Paraná: Train - {len(parana_train_dataset)}, Val - {len(parana_val_dataset)}, Test - {len(parana_test_dataset)}\")\n","print(f\"Rosario: Train - {len(rosario_train_dataset)}, Val - {len(rosario_val_dataset)}, Test - {len(rosario_test_dataset)}\")\n","print(f\"Santa Fe: Train - {len(santafe_train_dataset)}, Val - {len(santafe_val_dataset)}, Test - {len(santafe_test_dataset)}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R0hQA-Bl084C","executionInfo":{"status":"ok","timestamp":1743105437217,"user_tz":180,"elapsed":14,"user":{"displayName":"Rodrigo Echeveste","userId":"13291271408897853643"}},"outputId":"2add8855-6ae9-4a71-b6d3-3cabae7018c4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Paraná: Train - 174, Val - 58, Test - 58\n","Rosario: Train - 192, Val - 64, Test - 64\n","Santa Fe: Train - 222, Val - 74, Test - 74\n"]}]},{"cell_type":"code","source":["from torch.utils.data import ConcatDataset\n","\n","# Combine train datasets\n","train_dataset = ConcatDataset([parana_train_dataset, rosario_train_dataset, santafe_train_dataset])\n","\n","# Combine val datasets\n","val_dataset = ConcatDataset([parana_val_dataset, rosario_val_dataset, santafe_val_dataset])\n","\n","# Combine test datasets\n","test_dataset = ConcatDataset([parana_test_dataset, rosario_test_dataset, santafe_test_dataset])\n","\n","print(f\"Combined Train Dataset Size: {len(train_dataset)}\")\n","print(f\"Combined Val Dataset Size: {len(val_dataset)}\")\n","print(f\"Combined Test Dataset Size: {len(test_dataset)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DHcPBQuo16sp","executionInfo":{"status":"ok","timestamp":1743105437904,"user_tz":180,"elapsed":12,"user":{"displayName":"Rodrigo Echeveste","userId":"13291271408897853643"}},"outputId":"329178ae-8875-4260-e493-654bab74507d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Combined Train Dataset Size: 588\n","Combined Val Dataset Size: 196\n","Combined Test Dataset Size: 196\n"]}]},{"cell_type":"code","source":["# Saving images used for train, val and test\n","\n","# Output location\n","output_dir = \"LitoralArg_Model\"\n","os.makedirs(output_dir, exist_ok=True)\n","\n","train_image_filenames = []\n","train_image_filenames.extend(parana_dataset.img_labels.iloc[parana_train_dataset.indices]['file_name'].tolist())\n","train_image_filenames.extend(rosario_dataset.img_labels.iloc[rosario_train_dataset.indices]['file_name'].tolist())\n","train_image_filenames.extend(santafe_dataset.img_labels.iloc[santafe_train_dataset.indices]['file_name'].tolist())\n","train_images_df = pd.DataFrame({'file_name': train_image_filenames})\n","train_images_df.to_csv(os.path.join(output_dir, 'train_images.csv'), index=False)\n","\n","val_image_filenames = []\n","val_image_filenames.extend(parana_dataset.img_labels.iloc[parana_val_dataset.indices]['file_name'].tolist())\n","val_image_filenames.extend(rosario_dataset.img_labels.iloc[rosario_val_dataset.indices]['file_name'].tolist())\n","val_image_filenames.extend(santafe_dataset.img_labels.iloc[santafe_val_dataset.indices]['file_name'].tolist())\n","val_images_df = pd.DataFrame({'file_name': val_image_filenames})\n","val_images_df.to_csv(os.path.join(output_dir, 'val_images.csv'), index=False)\n","\n","test_image_filenames = []\n","test_image_filenames.extend(parana_dataset.img_labels.iloc[parana_test_dataset.indices]['file_name'].tolist())\n","test_image_filenames.extend(rosario_dataset.img_labels.iloc[rosario_test_dataset.indices]['file_name'].tolist())\n","test_image_filenames.extend(santafe_dataset.img_labels.iloc[santafe_test_dataset.indices]['file_name'].tolist())\n","test_images_df = pd.DataFrame({'file_name': test_image_filenames})\n","test_images_df.to_csv(os.path.join(output_dir, 'test_images.csv'), index=False)\n","\n"],"metadata":{"id":"TpN6BBzLKw4d"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-whYsFlk4QyI"},"source":["## Training the model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":515},"id":"qTNxJYXV4QyI","scrolled":false,"executionInfo":{"status":"error","timestamp":1743106574775,"user_tz":180,"elapsed":1135418,"user":{"displayName":"Rodrigo Echeveste","userId":"13291271408897853643"}},"outputId":"52c56d15-689e-47a1-ef5a-47470f5b3f1f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 0, Train loss: 0.4361, Val loss: 0.4835\n","Epoch: 1, Train loss: 0.4217, Val loss: 0.4440\n","Epoch: 2, Train loss: 0.4061, Val loss: 0.4274\n","Epoch: 3, Train loss: 0.3909, Val loss: 0.4082\n","Epoch: 4, Train loss: 0.3804, Val loss: 0.3972\n","Epoch: 5, Train loss: 0.3580, Val loss: 0.3919\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-f7ec9070f1ce>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Sum up batch loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Handle `CustomType` automatically\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m     \"\"\"\n\u001b[0;32m--> 398\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_collate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             return [\n\u001b[0m\u001b[1;32m    212\u001b[0m                 \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             return [\n\u001b[0;32m--> 212\u001b[0;31m                 \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m             ]  # Backwards compatibility.\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcollate_fn_map\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0melem_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcollate_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate_tensor_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_typed_storage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["from torch.utils.data import DataLoader\n","from torch.optim import Adam\n","from torch.nn import BCEWithLogitsLoss\n","\n","batch_size = 8\n","\n","# Create data loaders\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","\n","# Define optimizer and loss function\n","optimizer = Adam(model.parameters(), lr=0.001)\n","criterion = BCEWithLogitsLoss()  # For binary classification\n","\n","# Early stopping parameters\n","patience = 10  # Same patience as in Torres et al. (2023)\n","best_val_loss = float('inf')  # Initialize with a very high value\n","epochs_without_improvement = 0\n","\n","# Moving model to GPU if available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","train_loss_history = []\n","val_loss_history = []\n","\n","# Training loop\n","for epoch in range(100):\n","    model.train()\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        # Move data to the appropriate device (e.g., GPU if available)\n","        data, target = data.to(device), target.to(device)\n","\n","        optimizer.zero_grad()  # Reset gradients\n","        output = model(data)  # Forward pass\n","        loss = criterion(output, target.unsqueeze(1).float())  # Calculate loss\n","        loss.backward()  # Backpropagate\n","        optimizer.step()  # Update weights\n","\n","    # Computing Train and Val loss\n","    model.eval()\n","    train_loss = 0\n","    val_loss = 0\n","\n","    with torch.no_grad():\n","        for data, target in train_loader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            train_loss += criterion(output, target.unsqueeze(1).float()).item()  # Sum up batch loss\n","\n","        for data, target in val_loader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            val_loss += criterion(output, target.unsqueeze(1).float()).item()  # Sum up batch loss\n","\n","    train_loss /= len(train_loader)  # Average validation loss\n","    val_loss /= len(val_loader)  # Average validation loss\n","\n","    train_loss_history.append(train_loss)\n","    val_loss_history.append(val_loss)\n","\n","    print(f'Epoch: {epoch}, Train loss: {train_loss:.4f}, Val loss: {val_loss:.4f}')\n","\n","    # Early stopping check\n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        epochs_without_improvement = 0\n","        # You can save the best model here\n","        torch.save(model.state_dict(), os.path.join(output_dir, 'best_local_model.pth'))\n","    else:\n","        epochs_without_improvement += 1\n","        if epochs_without_improvement >= patience:\n","            print(f'Early stopping triggered after {epoch} epochs.')\n","            break\n","\n","\n","loss_history = pd.DataFrame({\n","    'train_loss': train_loss_history,\n","    'val_loss': val_loss_history\n","})\n","\n","loss_history.to_csv(os.path.join(output_dir, 'loss_history.csv'), index=False)\n"]},{"cell_type":"markdown","source":[],"metadata":{"id":"B_yaO77DPLPu"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"bfF0p1Gf4QyJ"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}