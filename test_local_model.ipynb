{"cells":[{"cell_type":"markdown","metadata":{"id":"MwOH7y-Q4Qx9"},"source":["# Finetuning a DCNN to detect landfills in the Litoral Region in Argentina"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"uL2SH35XA9mJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1744804769684,"user_tz":180,"elapsed":26187,"user":{"displayName":"Rodrigo Echeveste","userId":"13291271408897853643"}},"outputId":"176ebfd3-c705-4c2a-d372-c0450d974f5e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import sys, os\n","import numpy as np"],"metadata":{"id":"VXr7OVZ-oQoW","executionInfo":{"status":"ok","timestamp":1744804769693,"user_tz":180,"elapsed":31,"user":{"displayName":"Rodrigo Echeveste","userId":"13291271408897853643"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["project_directory = \"/content/drive/MyDrive/Trabajo/Proyectos/Basurales_Carla/cientibeca\"\n","os.chdir(project_directory)\n","print(f\"Current working directory: {os.getcwd()}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dalPDNqYpCw1","executionInfo":{"status":"ok","timestamp":1744804771418,"user_tz":180,"elapsed":1736,"user":{"displayName":"Rodrigo Echeveste","userId":"13291271408897853643"}},"outputId":"9314f9eb-4ecf-4ab1-b34a-b9abe11f42e0"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Current working directory: /content/drive/.shortcut-targets-by-id/1dmEJvNxrJ2abNEMaGXh_azjDZFbyVCn8/cientibeca\n"]}]},{"cell_type":"markdown","metadata":{"id":"GdGeoanR4QyF"},"source":["# Loading architecture and pre-trained weights"]},{"cell_type":"code","source":["!pip install pytorch-ignite"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hG9TjqHnDv1s","executionInfo":{"status":"ok","timestamp":1744804871501,"user_tz":180,"elapsed":100080,"user":{"displayName":"Rodrigo Echeveste","userId":"13291271408897853643"}},"outputId":"759d8b62-0e6c-4837-cb72-abc3f05400ae"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pytorch-ignite\n","  Downloading pytorch_ignite-0.5.2-py3-none-any.whl.metadata (27 kB)\n","Requirement already satisfied: torch<3,>=1.3 in /usr/local/lib/python3.11/dist-packages (from pytorch-ignite) (2.6.0+cu124)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from pytorch-ignite) (24.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.3->pytorch-ignite) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.3->pytorch-ignite) (4.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.3->pytorch-ignite) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.3->pytorch-ignite) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.3->pytorch-ignite) (2025.3.2)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3,>=1.3->pytorch-ignite)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3,>=1.3->pytorch-ignite)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3,>=1.3->pytorch-ignite)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3,>=1.3->pytorch-ignite)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3,>=1.3->pytorch-ignite)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3,>=1.3->pytorch-ignite)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3,>=1.3->pytorch-ignite)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3,>=1.3->pytorch-ignite)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3,>=1.3->pytorch-ignite)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.3->pytorch-ignite) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.3->pytorch-ignite) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.3->pytorch-ignite) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3,>=1.3->pytorch-ignite)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.3->pytorch-ignite) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.3->pytorch-ignite) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=1.3->pytorch-ignite) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=1.3->pytorch-ignite) (3.0.2)\n","Downloading pytorch_ignite-0.5.2-py3-none-any.whl (343 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m343.2/343.2 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m77.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, pytorch-ignite\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pytorch-ignite-0.5.2\n"]}]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yPrHdM7w4QyG","executionInfo":{"status":"ok","timestamp":1744804902797,"user_tz":180,"elapsed":31285,"user":{"displayName":"Rodrigo Echeveste","userId":"13291271408897853643"}},"outputId":"896c5526-8113-41ba-fd5e-53d191e81b88"},"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\n"]},{"output_type":"stream","name":"stdout","text":["pretrained\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 97.8M/97.8M [00:00<00:00, 246MB/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":5}],"source":["import torch\n","\n","sys.path.append(os.path.join(project_directory, 'modelo_italia'))\n","\n","# Importing model definition\n","from architecture.resnet50_fpn import Net\n","\n","# Loading state dictionary\n","STATE_DICT_PATH = \"LitoralArg_Model/best_local_model.pth\"\n","\n","# Creating an instance of the model\n","model = Net(num_classes=1)\n","\n","# Loading the weights into the model\n","model.load_state_dict(torch.load(STATE_DICT_PATH, map_location=torch.device('cpu')))"]},{"cell_type":"markdown","metadata":{"id":"po2KLpeG4QyG"},"source":["# Loading data"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"Tr4isnzP4QyH","executionInfo":{"status":"ok","timestamp":1744804906454,"user_tz":180,"elapsed":3656,"user":{"displayName":"Rodrigo Echeveste","userId":"13291271408897853643"}}},"outputs":[],"source":["import pandas as pd\n","db_parana = pd.read_csv(\"labels/parana_labels.csv\")\n","db_rosario = pd.read_csv(\"labels/rosario_labels.csv\")\n","db_santafe = pd.read_csv(\"labels/santafe_labels.csv\")\n","\n","list_test_images = pd.read_csv(\"LitoralArg_Model/test_images.csv\")\n","list_val_images = pd.read_csv(\"LitoralArg_Model/val_images.csv\")\n","list_train_images = pd.read_csv(\"LitoralArg_Model/train_images.csv\")\n","\n","db_parana_train = db_parana[db_parana['file_name'].isin(list_train_images['file_name'])]\n","db_parana_val = db_parana[db_parana['file_name'].isin(list_val_images['file_name'])]\n","db_parana_test = db_parana[db_parana['file_name'].isin(list_test_images['file_name'])]\n","\n","db_rosario_train = db_rosario[db_rosario['file_name'].isin(list_train_images['file_name'])]\n","db_rosario_val = db_rosario[db_rosario['file_name'].isin(list_val_images['file_name'])]\n","db_rosario_test = db_rosario[db_rosario['file_name'].isin(list_test_images['file_name'])]\n","\n","db_santafe_train = db_santafe[db_santafe['file_name'].isin(list_train_images['file_name'])]\n","db_santafe_val = db_santafe[db_santafe['file_name'].isin(list_val_images['file_name'])]\n","db_santafe_test = db_santafe[db_santafe['file_name'].isin(list_test_images['file_name'])]"]},{"cell_type":"code","source":["from torch.utils.data import Dataset\n","from PIL import Image\n","from torchvision import transforms\n","\n","train_val_transform = transforms.Compose([\n","            transforms.Resize(800), # Images are resized to 800x800 using the same resolution as inTorres et al. (2023)\n","            transforms.RandomHorizontalFlip(),  # Random horizontal flips as in Torres et al. (2023)\n","            transforms.RandomRotation(90), # Random 90-degree rotations as in Torres et al. (2023)\n","            transforms.ToTensor(),\n","            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                                 std=[0.229, 0.224, 0.225])  # ImageNet normalization\n","            ])\n","\n","test_transform = transforms.Compose([\n","            transforms.Resize(800), # Images are resized to 800x800 using the same resolution as inTorres et al. (2023)\n","            transforms.ToTensor(),\n","            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                                 std=[0.229, 0.224, 0.225])  # ImageNet normalization\n","            ])\n","\n","\n","class CustomImageDataset(Dataset):\n","    def __init__(self, dataframe, img_dir, transform):\n","        \"\"\"\n","        Args:\n","            dataframe (pandas.DataFrame): DataFrame containing image file names and labels.\n","            img_dir (str): Directory containing the images.\n","        \"\"\"\n","        self.img_labels = dataframe[['file_name', 'etiqueta']]\n","        self.img_dir = img_dir\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.img_labels)\n","\n","    def __getitem__(self, idx):\n","        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n","        image = Image.open(img_path).convert('RGB')\n","        label = self.img_labels.iloc[idx, 1]\n","\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        return image, label\n","\n","parana_dataset = CustomImageDataset(db_parana, 'images/parana/patches_parana',test_transform)\n","rosario_dataset = CustomImageDataset(db_rosario, 'images/rosario/patches_ros',test_transform)\n","santafe_dataset = CustomImageDataset(db_santafe, 'images/santa_fe/patches_sfe',test_transform)\n","\n","parana_test_dataset = CustomImageDataset(db_parana_test, 'images/parana/patches_parana',test_transform)\n","parana_val_dataset = CustomImageDataset(db_parana_val, 'images/parana/patches_parana',train_val_transform)\n","parana_train_dataset = CustomImageDataset(db_parana_train, 'images/parana/patches_parana',train_val_transform)\n","\n","rosario_test_dataset = CustomImageDataset(db_rosario_test, 'images/rosario/patches_ros',test_transform)\n","rosario_val_dataset = CustomImageDataset(db_rosario_val, 'images/rosario/patches_ros',train_val_transform)\n","rosario_train_dataset = CustomImageDataset(db_rosario_train, 'images/rosario/patches_ros',train_val_transform)\n","\n","santafe_test_dataset = CustomImageDataset(db_santafe_test, 'images/santa_fe/patches_sfe',test_transform)\n","santafe_val_dataset = CustomImageDataset(db_santafe_val, 'images/santa_fe/patches_sfe',train_val_transform)\n","santafe_train_dataset = CustomImageDataset(db_santafe_train, 'images/santa_fe/patches_sfe',train_val_transform)"],"metadata":{"id":"4bOzT7W40Y3q","executionInfo":{"status":"ok","timestamp":1744806302269,"user_tz":180,"elapsed":72,"user":{"displayName":"Rodrigo Echeveste","userId":"13291271408897853643"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import ConcatDataset\n","\n","# Combine train datasets\n","train_dataset = ConcatDataset([parana_train_dataset, rosario_train_dataset, santafe_train_dataset])\n","\n","# Combine val datasets\n","val_dataset = ConcatDataset([parana_val_dataset, rosario_val_dataset, santafe_val_dataset])\n","\n","# Combine test datasets\n","test_dataset = ConcatDataset([parana_test_dataset, rosario_test_dataset, santafe_test_dataset])\n","\n","print(f\"Combined Train Dataset Size: {len(train_dataset)}\")\n","print(f\"Combined Val Dataset Size: {len(val_dataset)}\")\n","print(f\"Combined Test Dataset Size: {len(test_dataset)}\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DHcPBQuo16sp","executionInfo":{"status":"ok","timestamp":1744804908268,"user_tz":180,"elapsed":25,"user":{"displayName":"Rodrigo Echeveste","userId":"13291271408897853643"}},"outputId":"c715a01a-b4a1-4e89-b5f8-1c537375e23b"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Combined Train Dataset Size: 588\n","Combined Val Dataset Size: 196\n","Combined Test Dataset Size: 196\n"]}]},{"cell_type":"markdown","metadata":{"id":"-whYsFlk4QyI"},"source":["## Testing the model"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qTNxJYXV4QyI","scrolled":false,"executionInfo":{"status":"ok","timestamp":1744805537830,"user_tz":180,"elapsed":629561,"user":{"displayName":"Rodrigo Echeveste","userId":"13291271408897853643"}},"outputId":"b70a033f-e9ab-4819-8647-b1c8583982f5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Evaluating model...\n","Evaluating train set...\n","Evaluating val set...\n","Evaluating test set...\n"]}],"source":["from torch.utils.data import DataLoader\n","from torch.optim import Adam\n","from torch.nn import BCEWithLogitsLoss\n","\n","batch_size = 8\n","\n","# Create data loaders\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","\n","def evaluate_model(model, dataloader, device):\n","    model.eval()\n","    predictions = []\n","    targets = []\n","\n","    with torch.no_grad():\n","        for data, target in dataloader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            predictions.extend(output.cpu().numpy())\n","            targets.extend(target.cpu().numpy())\n","\n","    return predictions, targets\n","\n","\n","# Moving model to GPU if available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","# Evaluating the model\n","print(\"Evaluating model...\")\n","print(\"Evaluating train set...\")\n","train_predictions, train_targets = evaluate_model(model, train_loader, device)\n","print(\"Evaluating val set...\")\n","val_predictions, val_targets = evaluate_model(model, val_loader, device)\n","print(\"Evaluating test set...\")\n","test_predictions, test_targets = evaluate_model(model, test_loader, device)\n"]},{"cell_type":"code","source":["def sigmoid(x):\n","    return 1/(1+(np.exp((-x))))\n","\n","train_predicted_scores = sigmoid(np.array(train_predictions)).tolist()\n","val_predicted_scores = sigmoid(np.array(val_predictions)).tolist()\n","test_predicted_scores = sigmoid(np.array(test_predictions)).tolist()\n","\n","train_predicted_labels = [1 if x > 0 else 0 for x in train_predictions]\n","val_predicted_labels = [1 if x > 0 else 0 for x in val_predictions]\n","test_predicted_labels = [1 if x > 0 else 0 for x in test_predictions]"],"metadata":{"id":"j4LquSLrjF55","executionInfo":{"status":"ok","timestamp":1744807511318,"user_tz":180,"elapsed":6,"user":{"displayName":"Rodrigo Echeveste","userId":"13291271408897853643"}}},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"B_yaO77DPLPu"}},{"cell_type":"code","execution_count":24,"metadata":{"id":"bfF0p1Gf4QyJ","executionInfo":{"status":"ok","timestamp":1744807513312,"user_tz":180,"elapsed":29,"user":{"displayName":"Rodrigo Echeveste","userId":"13291271408897853643"}}},"outputs":[],"source":["# Output location\n","output_dir = \"LitoralArg_Model\"\n","\n","train_image_filenames = db_parana_train['file_name'].tolist()\n","train_image_filenames.extend(db_rosario_train['file_name'].tolist())\n","train_image_filenames.extend(db_santafe_train['file_name'].tolist())\n","train_results_df = pd.DataFrame({'file_name': train_image_filenames, 'labels': train_targets, 'predicted_scores': train_predicted_scores, 'predicted_labels': train_predicted_labels})\n","train_results_df.to_csv(os.path.join(output_dir, 'train_results.csv'), index=False)\n","\n","\n","val_image_filenames = db_parana_val['file_name'].tolist()\n","val_image_filenames.extend(db_rosario_val['file_name'].tolist())\n","val_image_filenames.extend(db_santafe_val['file_name'].tolist())\n","val_results_df = pd.DataFrame({'file_name': val_image_filenames, 'labels': val_targets, 'predicted_scores': val_predicted_scores, 'predicted_labels': val_predicted_labels})\n","val_results_df.to_csv(os.path.join(output_dir, 'val_results.csv'), index=False)\n","\n","test_image_filenames = db_parana_test['file_name'].tolist()\n","test_image_filenames.extend(db_rosario_test['file_name'].tolist())\n","test_image_filenames.extend(db_santafe_test['file_name'].tolist())\n","test_results_df = pd.DataFrame({'file_name': test_image_filenames, 'labels': test_targets, 'predicted_scores': test_predicted_scores, 'predicted_labels': test_predicted_labels})\n","test_results_df.to_csv(os.path.join(output_dir, 'test_results.csv'), index=False)"]},{"cell_type":"code","source":["frac_pos_train_labels = np.sum(train_targets)/len(train_targets)\n","print(f\"Fraction of positive labels in train set: {frac_pos_train_labels}\")\n","\n","frac_pos_train_predictions = np.sum(train_predicted_labels)/len(train_predicted_labels)\n","print(f\"Fraction of positive predictions in train set: {frac_pos_train_predictions}\")\n","\n","frac_pos_test_labels = np.sum(test_targets)/len(test_targets)\n","print(f\"Fraction of positive labels in test set: {frac_pos_test_labels}\")\n","\n","frac_pos_test_predictions = np.sum(test_predicted_labels)/len(test_predicted_labels)\n","print(f\"Fraction of positive predictions in test set: {frac_pos_test_predictions}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aB5sIoh-e8Sp","executionInfo":{"status":"ok","timestamp":1744806655878,"user_tz":180,"elapsed":58,"user":{"displayName":"Rodrigo Echeveste","userId":"13291271408897853643"}},"outputId":"af1fef6b-f4f2-43dc-df77-64cb4acaa51a"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Fraction of positive labels in train set: 0.12755102040816327\n","Fraction of positive predictions in train set: 0.003401360544217687\n","Fraction of positive labels in test set: 0.09693877551020408\n","Fraction of positive predictions in test set: 0.00510204081632653\n"]}]},{"cell_type":"code","source":["acc_train = np.sum(np.array(train_targets) == np.array(train_predicted_labels))/len(train_targets)\n","acc_test = np.sum(np.array(test_targets) == np.array(test_predicted_labels))/len(test_targets)\n","\n","print(f\"Accuracy in train set: {acc_train}\")\n","print(f\"Accuracy in test set: {acc_test}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r5JFyhR3i6IQ","executionInfo":{"status":"ok","timestamp":1744807670928,"user_tz":180,"elapsed":25,"user":{"displayName":"Rodrigo Echeveste","userId":"13291271408897853643"}},"outputId":"e1b59b0e-569a-4425-ec0f-c7acdf78a6bf"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy in train set: 0.8724489795918368\n","Accuracy in test set: 0.9081632653061225\n"]}]},{"cell_type":"code","source":["def compute_balanced_accuracy(y_true, y_pred):\n","    if not isinstance(y_true, np.ndarray) or not isinstance(y_pred, np.ndarray):\n","        y_true, y_pred = np.array(y_true), np.array(y_pred)\n","    acc_pos = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_true == 1)\n","    acc_neg = np.sum((y_true == 0) & (y_pred == 0)) / np.sum(y_true == 0)\n","    balanced_acc = (acc_pos + acc_neg) / 2\n","    return balanced_acc\n","\n","bal_acc_train = compute_balanced_accuracy(train_targets, train_predicted_labels)\n","bal_acc_test = compute_balanced_accuracy(test_targets, test_predicted_labels)\n","\n","print(f\"Balanced accuracy in train set: {bal_acc_train}\")\n","print(f\"Balanced accuracy in test set: {bal_acc_test}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IZyZmT6epHe7","executionInfo":{"status":"ok","timestamp":1744807928706,"user_tz":180,"elapsed":9,"user":{"displayName":"Rodrigo Echeveste","userId":"13291271408897853643"}},"outputId":"f3980e57-4958-4579-9d52-2dcb2ce4359b"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Balanced accuracy in train set: 0.505692007797271\n","Balanced accuracy in test set: 0.5263157894736842\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"YaaWIoj2pW9d"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}